{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SmPBHnVvqlk7",
    "outputId": "af5041c9-8884-441d-beda-6388249bccd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\omoni\\anaconda3\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from datasets) (0.31.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: colorama in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\omoni\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\omoni\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\omoni\\anaconda3\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\omoni\\anaconda3\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\omoni\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\omoni\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\omoni\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\omoni\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U datasets\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ctS0C_TRiSOl"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563,
     "referenced_widgets": [
      "645c4cff05b247d08171faeb0ba3875c",
      "d5712fd10e53426bb8fa69662f6a5107",
      "8deb90e9e49743b6b57bffc0f7365c20",
      "2f3a6122b9d24fc5858264d0f38540be",
      "94fb78fb2e784f998aa9dc5e336f4a9e",
      "8ee283ca097f44c0a17619bebf0bf39a",
      "bb67ba38bd1a4930a0a1e45792b98001",
      "5f743ad2cfbf4766ab8e5398ca433821",
      "58adac8e319c41a599e6d10ed589427d",
      "968a277566c24617baf196c0d7d26c8c",
      "75aec13925f54e30b3237aeb05bdd920",
      "2a08e307fe79459ea2436edce5583e08",
      "185b1cf1a71a421e8896a589370958bd",
      "9ab4a07217724e60b6c2359c0e549412",
      "7ba379f4697f400b8fc1cc8f10e3bcdc",
      "c2cc8fcb38224a8c9edef245560ce50b",
      "c38942711bd34a87b7a9883c3f4dab9d",
      "9765bb6c982d42c581df4b7fd8bccf2a",
      "1ffeb90753204d7ab9e42fd99caaa38c",
      "bbacfde728aa407db46871b974c239fb",
      "2823346129884716a30e36b1ae6532fa",
      "d1b077a5f841413692a197cb23498fca",
      "c42bb1023209422dae7dadd2724ce730",
      "f9086ebf04bb4ab49284c9847186b759",
      "f07de1935e2e4d36919809041b42b162",
      "7fb3c57e61b34852b1906731fa689087",
      "6a84f00b6d864de6818a8492e3a53cae",
      "3170f79fccea4a0c8c82e5b30504d099",
      "1a8da375a260416a9764285dd27d50d5",
      "78e544d960a0480086c95c9dd51e155e",
      "a402dd74c07d4decb0704be9fe5583c6",
      "9617eac33afa4511b19bad4b58e4b0e4",
      "0b298eb2c5f44bca8cac1b64198be74e",
      "0241dff7e9d8418c8acb1af9011c53a9",
      "8e385481d77b4e08bdf5e262af71ad3c",
      "fe516c5d13b442b2ae10f0eda948743d",
      "999de95fb6604149aaa0968f277e9c97",
      "2b48edbcf9fc4110ba5b99d4e579cae9",
      "46ab47d91e874661aef63a8e3e47f543",
      "e39b02e95d1440b0b558194a0c2c7bf3",
      "3ff245206ae64ad99054b55eef7cb1ad",
      "8c714a582cc347fe9c1c6ed1e806b109",
      "e8b93636a3f743669234ed58783d2e92",
      "ffdfb6416de249ea8c88150852db3545",
      "4f6109faa86d43c68dd1f112513d1316",
      "78a4082559b04024b26420d97ef47f55",
      "c60e586cd5474befad22353fa15dfa30",
      "b1d1cdcb7a7b437bbd8e5f06ecf0e147",
      "bf32328f18c540b3b89486f1e53baf03",
      "df3899cce99d4caabe87498e22291780",
      "8d312b2c5f5343cda5af9f741d14feec",
      "342fec11459448f5a3ef553546c40cdf",
      "488d47db354947d5a1c14a71517f79cd",
      "d0cccaedaec94a059a0451f40bb24aa9",
      "d0a8d86445de4cca99488962c760014e",
      "df661a7d919b4cc883207c7e3779506d",
      "7b5f48b34a064f06889e4ec52eb7c8d0",
      "0680cd9734ea44bea14ebd5428500de0",
      "d7f0373ecbf74d77a30039419210879c",
      "da5e74250a1246b587634f5c7af78503",
      "8b09935f05434af1b928afd67e58d837",
      "b07b919f2eef48d4bad1520546820d47",
      "49e20829ca5e493ba83995313918a376",
      "ac941c17594444f5bac244565b2bcc76",
      "c0122db8c463401f81911887bb6a8b90",
      "5814129bf73d4e7481e6a01d63e1794d",
      "54d20546fbd347a785e0c2192d04bb33",
      "c15cf8b387054e9f9f346bb488505443",
      "9ff07499ec874f39a3a4708f2aeb6bd8",
      "5b9d36e65aae4998952b11258ec28399",
      "3fb7abba6cf84b0e8ebb0b9fad34b088",
      "4be0017caaef4b39bc5d1426858c8051",
      "6c0751ded4df4ae98b765debf41feb28",
      "40482b377d9d45bcbf069f52dfa471fa",
      "c7e262994ad84124803f0f1130983d94",
      "3eb14000ba8d48faa1a293329be61d4f",
      "2df12f8671f74c89acc640f8fb186d38",
      "8c6826e1b48145769c55debdc0b75d29",
      "fa895c5feb7b4679ae7d49414f793c90",
      "e9045fbf6d954e85bfe026bc20b7c808",
      "6aec4e070899458cad6edccbb1aff1d5",
      "69e2f1c3d55643c38dcb169b41d7b726",
      "dec3424fdaa14566b3cf5cbdbb134ba4",
      "187dda124cdf483bad5096b627df689a",
      "ec417bf5532244748a96e4b3c9de33e2",
      "dbdf912a44774090a84acd65048f2ac9",
      "3a16e08acbb14a1f8c06ebcf62fee001",
      "f2979b1f72b048d1bf2578f8fd1341eb",
      "e162b9aef8834d088bc4b158fa2a7f31",
      "236705ce657d47a59e4ad644b94a10a9",
      "31a31fea596b4f079a8e9de5920b5019",
      "cd67f16a4d4a49fa9ad21fb36921f5a9",
      "8a002c539275425a83c5e7a16ece6f25",
      "2cb7427dae34409b997dbdc1e9bf28ee",
      "896fc885b4e846a9877c4a12ec2f220c",
      "d073ef8e930f4d45897ce9145a2b8c7b",
      "9d6c51711df6423fb1cd8021e8cf0821",
      "19df478e041e4771b97e4863d3c71206",
      "cd42823411af44b387143da9c47df8c6",
      "737b191a42724618b62dceb2ccc03b86",
      "29c039a0d27941ec93adeec118c0f6fb",
      "ae4dbc5d039c429c9b903da915c4cdeb",
      "02fc60ed0dcf410e9d3001ec7174a0e0",
      "4d3e24f08e7d4595b7b5b8a09bee005f",
      "5532f265fb494758bb726d62e1d7ac00",
      "ab99334cf8ba4a1f9c3946b56586ef75",
      "767c3be8031b4a1094f290457bd8a9ee",
      "d3d47a2e2c654f73afcbc3f918bc05bb",
      "432c2a01669c474d9f0d6d7990c96a3e",
      "c986f798fe9049799e1074dbfbec1f00",
      "9cada76dbbe54faf8f2065ba76450470",
      "2b1065103ed343f391e7e9dbdc99af4b",
      "f72a50b5f49147fe906ec904379255d9",
      "6c36682c30ec4dc0a33f38fe17d44539",
      "4eb3311e5f0849168cc6fa1a8f2ef652",
      "0de3cfd0217944cf8512be2733eb55fd",
      "497346c44c79410a8dd81d439cd81b75",
      "d1e477e360994fc38b7927e392c9f8c1",
      "edf026eeec284d44a67f52ccd0b34f7d",
      "edc1731fb8e64d5f91fd57eb8c7e121c",
      "a091d79f08e4486ba6f31d799ecda5c7"
     ]
    },
    "id": "iLTdskAPj3yx",
    "outputId": "f10086c3-cef5-4a00-a1b3-aa1b0db32d82"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21749f017f44eb0a0a1321f9a7fcab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\omoni\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\omoni\\.cache\\huggingface\\hub\\datasets--multi_news. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0298d94be2fb43a8bf32034151c9e98b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "multi_news.py:   0%|          | 0.00/3.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The repository for multi_news contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/multi_news.\nPlease pass the argument `trust_remote_code=True` to allow custom code to be run.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ds \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti_news\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\omoni\\anaconda3\\Lib\\site-packages\\datasets\\load.py:2062\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[0;32m   2057\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[0;32m   2058\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[0;32m   2059\u001b[0m )\n\u001b[0;32m   2061\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[1;32m-> 2062\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m load_dataset_builder(\n\u001b[0;32m   2063\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m   2064\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   2065\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[0;32m   2066\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[0;32m   2067\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   2068\u001b[0m     features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[0;32m   2069\u001b[0m     download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[0;32m   2070\u001b[0m     download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[0;32m   2071\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   2072\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   2073\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   2074\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[0;32m   2075\u001b[0m     _require_default_config_name\u001b[38;5;241m=\u001b[39mname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2076\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_kwargs,\n\u001b[0;32m   2077\u001b[0m )\n\u001b[0;32m   2079\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[0;32m   2080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[1;32mc:\\Users\\omoni\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1782\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[0;32m   1781\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[1;32m-> 1782\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m dataset_module_factory(\n\u001b[0;32m   1783\u001b[0m     path,\n\u001b[0;32m   1784\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   1785\u001b[0m     download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[0;32m   1786\u001b[0m     download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[0;32m   1787\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[0;32m   1788\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[0;32m   1789\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   1790\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[0;32m   1791\u001b[0m     _require_default_config_name\u001b[38;5;241m=\u001b[39m_require_default_config_name,\n\u001b[0;32m   1792\u001b[0m     _require_custom_configs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(config_kwargs),\n\u001b[0;32m   1793\u001b[0m )\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[0;32m   1795\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[1;32mc:\\Users\\omoni\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1664\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[0;32m   1659\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1660\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1661\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any data file at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1662\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on the Hugging Face Hub either: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e1)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1663\u001b[0m                     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1664\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m trust_remote_code:\n\u001b[0;32m   1666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1667\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a dataset script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or any data file in the same directory.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1668\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\omoni\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1614\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[0;32m   1605\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1606\u001b[0m     \u001b[38;5;66;03m# Otherwise we must use the dataset script if the user trusts it\u001b[39;00m\n\u001b[0;32m   1607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m HubDatasetModuleFactoryWithScript(\n\u001b[0;32m   1608\u001b[0m         path,\n\u001b[0;32m   1609\u001b[0m         commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[0;32m   1610\u001b[0m         download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[0;32m   1611\u001b[0m         download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[0;32m   1612\u001b[0m         dynamic_modules_path\u001b[38;5;241m=\u001b[39mdynamic_modules_path,\n\u001b[0;32m   1613\u001b[0m         trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[1;32m-> 1614\u001b[0m     )\u001b[38;5;241m.\u001b[39mget_module()\n\u001b[0;32m   1615\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n\u001b[0;32m   1616\u001b[0m     \u001b[38;5;66;03m# Use the infos from the parquet export except in some cases:\u001b[39;00m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_dir \u001b[38;5;129;01mor\u001b[39;00m data_files \u001b[38;5;129;01mor\u001b[39;00m (revision \u001b[38;5;129;01mand\u001b[39;00m revision \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\omoni\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1264\u001b[0m, in \u001b[0;36mHubDatasetModuleFactoryWithScript.get_module\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1257\u001b[0m importable_file_path \u001b[38;5;241m=\u001b[39m _get_importable_file_path(\n\u001b[0;32m   1258\u001b[0m     dynamic_modules_path\u001b[38;5;241m=\u001b[39mdynamic_modules_path,\n\u001b[0;32m   1259\u001b[0m     module_namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1260\u001b[0m     subdirectory_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mhash\u001b[39m,\n\u001b[0;32m   1261\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m   1262\u001b[0m )\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(importable_file_path):\n\u001b[1;32m-> 1264\u001b[0m     trust_remote_code \u001b[38;5;241m=\u001b[39m resolve_trust_remote_code(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrust_remote_code, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trust_remote_code:\n\u001b[0;32m   1266\u001b[0m         _create_importable_file(\n\u001b[0;32m   1267\u001b[0m             local_path\u001b[38;5;241m=\u001b[39mlocal_path,\n\u001b[0;32m   1268\u001b[0m             local_imports\u001b[38;5;241m=\u001b[39mlocal_imports,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1274\u001b[0m             download_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_mode,\n\u001b[0;32m   1275\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\omoni\\anaconda3\\Lib\\site-packages\\datasets\\load.py:137\u001b[0m, in \u001b[0;36mresolve_trust_remote_code\u001b[1;34m(trust_remote_code, repo_id)\u001b[0m\n\u001b[0;32m    134\u001b[0m         signal\u001b[38;5;241m.\u001b[39malarm(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;66;03m# OS which does not support signal.SIGALRM\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    138\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe repository for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m contains custom code which must be executed to correctly \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload the dataset. You can inspect the repository content at https://hf.co/datasets/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease pass the argument `trust_remote_code=True` to allow custom code to be run.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m         )\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;66;03m# For the CI which might put the timeout at 0\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     _raise_timeout_error(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: The repository for multi_news contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/multi_news.\nPlease pass the argument `trust_remote_code=True` to allow custom code to be run."
     ]
    }
   ],
   "source": [
    "ds = load_dataset('multi_news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S96d2ulVjujI",
    "outputId": "5b3c5e66-fa6a-4ebb-ff47-83b0625c8389"
   },
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QCKtC0AskN1J",
    "outputId": "b8cf7f7d-6e55-4268-8d10-5342c82d905d"
   },
   "outputs": [],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hJ2moFYWk-Tc",
    "outputId": "327a6132-4609-4594-f973-bedc3b707a31"
   },
   "outputs": [],
   "source": [
    "ds['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6ZfjI3qlDms"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ds_train = pd.DataFrame(ds['train'])\n",
    "ds_train = ds_train.head(1000)\n",
    "ds_test = pd.DataFrame(ds['test'])\n",
    "ds_test = ds_test.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "LjL4AHuWnCL1",
    "outputId": "b68c219d-738f-48e7-ceef-6c71545216f5"
   },
   "outputs": [],
   "source": [
    "ds_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D1-ka-FwoQ3Q"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "# defining remove punctuation function\n",
    "def remove_punctuation(dataset):\n",
    "    dataset = \"\".join([char for char in dataset if char not in string.punctuation])\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wtPtKjKcG9a5"
   },
   "outputs": [],
   "source": [
    "# removing punctuation from both dataframes\n",
    "ds_train['document_no_punct'] = ds_train['document'].apply(lambda x: remove_punctuation(x))\n",
    "ds_test['document_no_punct'] = ds_test['document'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNcqWgr4J5tV"
   },
   "outputs": [],
   "source": [
    "# defining function to tokenize data\n",
    "def tokenize(review):\n",
    "    tokens = review.lower().split()\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "enKgaEu9N83V"
   },
   "outputs": [],
   "source": [
    "# tokenizing no punctuation documents\n",
    "ds_train['document_tokenizedt'] = ds_train['document_no_punct'].apply(lambda x: tokenize(x))\n",
    "ds_test['document_tokenizedt'] = ds_test['document_no_punct'].apply(lambda x: tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o58qDjShWOPV",
    "outputId": "1eaf771a-35cb-4f50-e45e-2ea5437edd1a"
   },
   "outputs": [],
   "source": [
    "# minimum number of words\n",
    "ds_train['document_tokenizedt'].apply(len).min()\n",
    "\n",
    "\n",
    "# maximum number of words\n",
    "ds_train['document_tokenizedt'].apply(len).max()\n",
    "\n",
    "\n",
    "# average number of words\n",
    "ds_train['document_tokenizedt'].apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_MGDmxXWhPM",
    "outputId": "dac4f02c-48d4-469c-9d68-5d23385ad580"
   },
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTwvCMb1WiOe",
    "outputId": "99fc0978-c974-43ed-f748-298d5a6c6b45"
   },
   "outputs": [],
   "source": [
    "# importing stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1XiNpIZZjDP"
   },
   "outputs": [],
   "source": [
    "# defining function that removes stopwords\n",
    "def remove_stopwords(review):\n",
    "    review = [word for word in review if word not in stop_words]\n",
    "\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2UWn-zFZmBS"
   },
   "outputs": [],
   "source": [
    "# removing stopwords on both dataframes\n",
    "ds_train['document_no_stop'] = ds_train['document_tokenizedt'].apply(lambda x: remove_stopwords(x))\n",
    "ds_test['document_no_stop'] = ds_test['document_tokenizedt'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YklnlMMfdZgI",
    "outputId": "abc9443b-19e6-4109-d67b-b9602a5ba5d8"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SiiuGA-NzEy6"
   },
   "outputs": [],
   "source": [
    "# instantiating the stemmer\n",
    "stemmer = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2kpmZaEdZ0z",
    "outputId": "f1491614-ffaa-4e07-c591-a14caf944731"
   },
   "outputs": [],
   "source": [
    "!pip install swifter\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "8be662528859423ca7eecc152fdba9a5",
      "140412565abc43ceab5a9cf014454598",
      "fe2c4137141741bc8a6984a86b744904",
      "941efb74e99b4708a57b0038e8189bec",
      "f86c0e76d1d6413683ca1bb0f7552ae4",
      "6bef937374fe4bf1b57ea436edb44d17",
      "34270023321a4ed891e75d7cdbc21a8e",
      "22a3dc9cbdba4cb8b78ce3a726339141",
      "855a54d750b34dc5b809e0c3316f5f0d",
      "4e3ccc6b2a9542e892c804e3e997bc20",
      "1f6a7ba628134a1f95e5e1929c7dedfd",
      "32093525b9af44b6b583b36f1b6f6d92",
      "2c34ae6f2b0a4d1c9c431917c33dec5e",
      "c5cc4069244e4b429dda3365515a1f55",
      "0db5f5db29e14614a8b77f1d7c4e273e",
      "f0599845183f40848ce8dd27e0a9ecc8",
      "260519282f3f468fb86929d0aa3b6c2b",
      "4ed01ebb4bf846a69a68f90ca4d3d6d5",
      "0b0d99353c0348f89eac5dcc3c312261",
      "42825d95898442c89bc4162acb30b6be",
      "4c9058c7d3c44cb8bbe62612901aa143",
      "57de8e8dca1240faa1e0d9ebe54e6a29"
     ]
    },
    "id": "o1NCtKdz_Jvq",
    "outputId": "930fdc5b-5f2b-4e97-957e-6e5bb9221af3"
   },
   "outputs": [],
   "source": [
    "ds_train['document_stemmed'] = ds_train['document_no_stop'].swifter.apply(\n",
    "    lambda tokens: [stemmer.stem(token) for token in tokens]\n",
    ")\n",
    "ds_test['document_stemmed'] = ds_test['document_no_stop'].swifter.apply(\n",
    "    lambda tokens: [stemmer.stem(token) for token in tokens]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "K48d5QyUHn2K",
    "outputId": "5298c7de-0071-4309-c9ed-d0a31f02eaaf"
   },
   "outputs": [],
   "source": [
    "ds_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LrqjA_URHa7l",
    "outputId": "06806433-487d-4d5e-aec9-4e2087dd3132"
   },
   "outputs": [],
   "source": [
    "# import Lemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# instantiate the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBkfKMgBIExO"
   },
   "outputs": [],
   "source": [
    "# lemmatizing all tokens as verbs\n",
    "ds_train['document_lemmatized_v'] = ds_train['document_no_stop'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token, pos='v') for token in tokens]\n",
    ")\n",
    "ds_test['document_lemmatized_v'] = ds_test['document_no_stop'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token, pos='v') for token in tokens]\n",
    ")\n",
    "\n",
    "\n",
    "# lemmatizing all tokens as adjectives\n",
    "ds_train['document_lemmatized_a'] = ds_train['document_no_stop'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token, pos='a') for token in tokens]\n",
    ")\n",
    "ds_test['document_lemmatized_a'] = ds_test['document_no_stop'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token, pos='a') for token in tokens]\n",
    ")\n",
    "\n",
    "\n",
    "# lemmatizing all tokens as adverbs\n",
    "ds_train['document_lemmatized_r'] = ds_train['document_no_stop'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token, pos='r') for token in tokens]\n",
    ")\n",
    "ds_test['document_lemmatized_r'] = ds_test['document_no_stop'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token, pos='r') for token in tokens]\n",
    ")\n",
    "\n",
    "\n",
    "# lemmatizing all tokens as satellite adjectives\n",
    "ds_train['document_lemmatized_s'] = ds_train['document_no_stop'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token, pos='s') for token in tokens]\n",
    ")\n",
    "ds_test['document_lemmatized_s'] = ds_test['document_no_stop'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token, pos='s') for token in tokens]\n",
    ")\n",
    "\n",
    "\n",
    "# lemmatizing all tokens with default POS (noun)\n",
    "ds_train['document_lemmatized_n'] = ds_train['document_no_stop'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token) for token in tokens]\n",
    ")\n",
    "ds_test['document_lemmatized_n'] = ds_test['document_no_stop'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token) for token in tokens]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "-Zfn8STpHeLQ",
    "outputId": "096afe57-1815-435e-b24d-65b0c6c864ad"
   },
   "outputs": [],
   "source": [
    "ds_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m22VEBJhnV79",
    "outputId": "89b16954-d0a7-48d3-b1e2-fdbb5151745e"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "# assign the splits\n",
    "train = Dataset.from_pandas(ds_train)\n",
    "test = Dataset.from_pandas(ds_test)\n",
    "# reconstruct both datasets into a Dataset Dict object\n",
    "new_ds = DatasetDict(\n",
    "    {\n",
    "        'train': train,\n",
    "        'test': test\n",
    "    }\n",
    ")\n",
    "# view the resulting dataset dict object\n",
    "new_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "774ba2744ec04400a8571edeb0a74b70",
      "6ba6cc4477a5492eb4d56cc056036235",
      "0b81de6d7fb64561886dbe3bb2633c4e",
      "7c2a88abd0bb4febafb7500cac4498b0",
      "fc21207a4eee459998ad029a90746d19",
      "bc17377378be42f28921084027ae8726",
      "4a9bdb5e6f884f2f9ea8ddba2a500090",
      "1591b2f3458745c7bbf84a161188d4bd",
      "fba04164fd374759b2ef3cc5461c998d",
      "37c1808c65c8473ab4bb8df4a9e1fdc6",
      "b48918b92b0c4291a3e4fb96fb6dd9e5",
      "1d767098ebc54e41ad85e8d6d7fd3486",
      "5051ff426b3b40b392b346b3b3df19dd",
      "0c9a1173f51746acacd212a507ba4991",
      "1fdf69ff8e754ce3b4018b0b9eaef2cb",
      "041af420bde44b089f4441f67c82572c",
      "c534486428794cc8abd754dab7fb4a7f",
      "6b5d149463b142d98d38815925869b57",
      "26400d3c6ce0459cae6db34b5dc2098d",
      "73c2f50a8c2e4606897e300261a7bd10",
      "70c64d35e1544739a3b4d84444141339",
      "07e61f2134eb4b6dab0b0a673ce82966"
     ]
    },
    "id": "Z2q8Z92xzerb",
    "outputId": "ed13619d-027b-41a7-cc34-e5be623f5ef7"
   },
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "new_ds.save_to_disk('/content/my_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M4B94I48pM6P",
    "outputId": "a63a01e9-1191-4d74-fb5c-cdc5c9fa4775"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!cp -r /content/my_dataset /content/drive/MyDrive/my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3AzO4Kr-mOZg"
   },
   "outputs": [],
   "source": [
    "!cp -r /content/my_dataset /content/drive/MyDrive/my_dataset"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
